{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_Assignment1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Courior/hello-world/blob/master/DeepLearning_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qrmE3yavTfYk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Part A - Tensorflow and Low Level API**"
      ]
    },
    {
      "metadata": {
        "id": "K6qNyijoTv8k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*(i) Two Layer Classifier*"
      ]
    },
    {
      "metadata": {
        "id": "MA15M7_BgU5X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GJQUAdv3hH7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6f054412-e1c1-4644-a38e-e88cd52ec604"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_dress_images = train_images[train_labels == 3]\n",
        "train_bag_images = train_images[train_labels == 8]\n",
        "train_dress_bag_images = np.append(train_dress_images, train_bag_images, axis=0)\n",
        "train_dress_labels = np.zeros((len(train_dress_images),), dtype=float)\n",
        "train_bag_labels = np.ones((len(train_bag_images),), dtype=float)\n",
        "train_dress_bag_labels = np.append(train_dress_labels, train_bag_labels, axis=0)\n",
        "\n",
        "test_dress_images = test_images[test_labels == 3]\n",
        "test_bag_images = test_images[test_labels == 8]\n",
        "test_dress_bag_images = np.append(test_dress_images, test_bag_images, axis=0)\n",
        "test_dress_labels = np.zeros((len(test_dress_images),), dtype=float)\n",
        "test_bag_labels = np.ones((len(test_bag_images),), dtype=float)\n",
        "test_dress_bag_labels = np.append(test_dress_labels, test_bag_labels, axis=0)\n",
        "\n",
        "print(len(train_images))\n",
        "print(len(train_dress_bag_images))\n",
        "print(len(train_dress_images))\n",
        "print(train_dress_bag_labels)\n",
        "# Reshape training dataset so that the features are flattened\n",
        "train_dress_bag_images = train_dress_bag_images.reshape(train_dress_bag_images.shape[0], -1).astype('float32')\n",
        "test_dress_bag_images = test_dress_bag_images.reshape(test_dress_bag_images.shape[0], -1).astype('float32')\n",
        "\n",
        "train_dress_bag_images = train_dress_bag_images.T\n",
        "test_dress_bag_images = test_dress_bag_images.T\n",
        "train_dress_bag_labels = np.reshape(train_dress_bag_labels, (-1,1)).T\n",
        "test_dress_bag_labels = np.reshape(test_dress_bag_labels, (-1,1)).T\n",
        "print(test_dress_bag_labels.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "12000\n",
            "6000\n",
            "[0. 0. 0. ... 1. 1. 1.]\n",
            "<class 'tuple'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3EptijJtvZBs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_Iterations= 1000\n",
        "display_step= 100\n",
        "\n",
        "\n",
        "# Model Params\n",
        "n_inputs = 784\n",
        "n_hidden = 100\n",
        "n_outputs=1\n",
        "learning_rate= 0.01\n",
        "n_epochs = 40\n",
        "\n",
        "#training label data\n",
        "x = tf.placeholder(tf.float32, [n_inputs,None])\n",
        "y_ = tf.placeholder(tf.float32, [1,None])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6oXd1cc6z1C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "1b1d65ab-8cdb-49bf-87af-12decfc980eb"
      },
      "cell_type": "code",
      "source": [
        "# Weight Bias for each layer\n",
        "W1 = tf.get_variable(\"W1\", [n_hidden, n_inputs], initializer = tf.glorot_uniform_initializer(seed=1))\n",
        "B1 = tf.get_variable(\"b1\", [n_hidden, 1], initializer = tf.zeros_initializer())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e6PDp0niveO9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W2 = tf.get_variable(\"W2\", [n_outputs, n_hidden], initializer = tf.glorot_uniform_initializer(seed=1))\n",
        "B2 = tf.get_variable(\"b2\", [n_outputs, 1], initializer = tf.zeros_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tLT9q4AW7oS6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "A1 = tf.add(tf.matmul(W1, x), B1)\n",
        "H1 = tf.nn.relu(A1)\n",
        "\n",
        "W2_T = tf.transpose(W2) \n",
        "\n",
        "y_pred = tf.add(tf.matmul(W2, H1),B2)\n",
        "y_pred_sigmoid = tf.sigmoid(y_pred) \n",
        "\n",
        "x_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred, labels=y_)\n",
        "loss = tf.reduce_mean(x_entropy)\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "predictions = tf.round(y_pred_sigmoid)\n",
        "predictions_correct = tf.cast(tf.equal(predictions, y_), tf.float32)\n",
        "accuracy = tf.reduce_mean(predictions_correct)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TXSD-IrrRHJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8867b9d-acda-4934-9a66-416bc713e26b"
      },
      "cell_type": "code",
      "source": [
        "print(train_dress_bag_images.dtype)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i-p0u9MkJXCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "2ec74f05-1d73-4752-e67f-a6efcc83f58a"
      },
      "cell_type": "code",
      "source": [
        "#Start training\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for epoch in range(n_epochs):\n",
        "    _, currentLoss, acc = sess.run([train_step, loss, accuracy], feed_dict={x: train_dress_bag_images, y_:train_dress_bag_labels})\n",
        "    print (currentLoss, \" \", acc)\n",
        "  print (\"Final Validation Accuracy \", sess.run(accuracy, feed_dict={x: test_dress_bag_images, y_: test_dress_bag_labels}))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33.430927   0.40441668\n",
            "1067.6387   0.6835833\n",
            "172766.23   0.5\n",
            "7.5709667   0.8516667\n",
            "9.246185   0.85791665\n",
            "0.5991754   0.58466667\n",
            "0.5312035   0.63341665\n",
            "0.598174   0.717\n",
            "0.5025573   0.83533335\n",
            "0.38415045   0.89625\n",
            "0.19672711   0.9425833\n",
            "0.14551131   0.9543333\n",
            "0.13506822   0.96383333\n",
            "0.12844925   0.9636667\n",
            "0.12266154   0.9658333\n",
            "0.11740979   0.96708333\n",
            "0.11266065   0.96825\n",
            "0.10843703   0.9688333\n",
            "0.10479594   0.9694167\n",
            "0.10151072   0.97041667\n",
            "0.09854318   0.9711667\n",
            "0.095901966   0.9715833\n",
            "0.09347045   0.97241664\n",
            "0.0911652   0.97275\n",
            "0.089015715   0.9730833\n",
            "0.08698284   0.9735\n",
            "0.085074514   0.97425\n",
            "0.08328893   0.97475\n",
            "0.08157738   0.9751667\n",
            "0.07996168   0.97583336\n",
            "0.07834204   0.9763333\n",
            "0.07672032   0.9765\n",
            "0.07521229   0.97675\n",
            "0.07400995   0.97675\n",
            "0.07305372   0.97675\n",
            "0.072134726   0.9769167\n",
            "0.071307614   0.9773333\n",
            "0.0705288   0.9775\n",
            "0.06978875   0.97783333\n",
            "0.069073886   0.97825\n",
            "Final Validation Accuracy  0.973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tAbwKEYdUAQ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(ii) Multi Class Classification"
      ]
    },
    {
      "metadata": {
        "id": "hdmpaMgJUO2e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_Train = train_images.reshape(train_images.shape[0], -1).astype('float32')\n",
        "X_test = test_images.reshape(test_images.shape[0], -1).astype('float32')\n",
        "# Normalize training data\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0\n",
        "X_train = X_train.T\n",
        "X_test = X_test.T\n",
        "# Convert labels to one-hot-encoded\n",
        "number_of_classes = 10\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, number_of_classes)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, number_of_classes)\n",
        "# Transpose train labels so that dimensions\n",
        "# are number of classes * number of instances\n",
        "Y_train = Y_train.T\n",
        "Y_test = Y_test.T\n",
        "print (\"Data extracted and reshaped: \")\n",
        "print (X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
        "\n",
        "# Model Params\n",
        "n_inputs = 784\n",
        "n_layer_1 = 300\n",
        "n_layer_2 = 100\n",
        "n_outputs=10\n",
        "learning_rate= 0.01\n",
        "n_epochs = 40\n",
        "\n",
        "#training label data\n",
        "x = tf.placeholder(tf.float32, [n_inputs,None])\n",
        "y_ = tf.placeholder(tf.float32, [1,None])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}